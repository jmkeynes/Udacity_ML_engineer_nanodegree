Simulator.run(): Trial 0
Environment.reset(): Trial set up with start = (7, 1), destination = (3, 6), deadline = 45
LearningAgent.update(): total_reward = 5.0, total_moves = 46, penalty = -17.0, location = (4, 1), destination = (3, 6)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 1
Environment.reset(): Trial set up with start = (2, 6), destination = (6, 2), deadline = 40
LearningAgent.update(): total_reward = 4.0, total_moves = 41, penalty = -16.0, location = (4, 3), destination = (6, 2)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 2
Environment.reset(): Trial set up with start = (5, 3), destination = (7, 5), deadline = 20
LearningAgent.update(): total_reward = 9.5, total_moves = 21, penalty = -6.5, location = (2, 2), destination = (7, 5)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 3
Environment.reset(): Trial set up with start = (5, 3), destination = (3, 1), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 16.5, total_moves = 20, penalty = -7.5, location = (3, 2), destination = (3, 1)
Simulator.run(): Trial 4
Environment.reset(): Trial set up with start = (3, 1), destination = (4, 5), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 14.0, total_moves = 7, penalty = -2.0, location = (4, 6), destination = (4, 5)
Simulator.run(): Trial 5
Environment.reset(): Trial set up with start = (1, 1), destination = (5, 3), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 32.5, total_moves = 26, penalty = -3.5, location = (5, 2), destination = (5, 3)
Simulator.run(): Trial 6
Environment.reset(): Trial set up with start = (6, 6), destination = (5, 3), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 13.0, total_moves = 11, penalty = -5.0, location = (5, 2), destination = (5, 3)
Simulator.run(): Trial 7
Environment.reset(): Trial set up with start = (1, 4), destination = (7, 6), deadline = 40
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 24.0, total_moves = 13, penalty = -2.0, location = (6, 6), destination = (7, 6)
Simulator.run(): Trial 8
Environment.reset(): Trial set up with start = (5, 4), destination = (7, 2), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 23.0, total_moves = 17, penalty = -3.0, location = (7, 3), destination = (7, 2)
Simulator.run(): Trial 9
Environment.reset(): Trial set up with start = (1, 3), destination = (3, 5), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 15.5, total_moves = 4, penalty = -0.5, location = (3, 4), destination = (3, 5)
Simulator.run(): Trial 10
Environment.reset(): Trial set up with start = (8, 3), destination = (5, 5), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 19.5, total_moves = 11, penalty = -2.5, location = (4, 5), destination = (5, 5)
Simulator.run(): Trial 11
Environment.reset(): Trial set up with start = (2, 6), destination = (6, 1), deadline = 45
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 38.0, total_moves = 20, penalty = -2.0, location = (6, 2), destination = (6, 1)
Simulator.run(): Trial 12
Environment.reset(): Trial set up with start = (4, 6), destination = (7, 1), deadline = 40
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 32.5, total_moves = 21, penalty = -3.5, location = (7, 2), destination = (7, 1)
Simulator.run(): Trial 13
Environment.reset(): Trial set up with start = (1, 4), destination = (2, 1), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 30.5, total_moves = 17, penalty = -1.5, location = (2, 2), destination = (2, 1)
Simulator.run(): Trial 14
Environment.reset(): Trial set up with start = (7, 1), destination = (4, 6), deadline = 40
LearningAgent.update(): total_reward = 41.0, total_moves = 41, penalty = -9.0, location = (4, 4), destination = (4, 6)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 15
Environment.reset(): Trial set up with start = (2, 2), destination = (8, 1), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 31.5, total_moves = 20, penalty = -2.5, location = (8, 2), destination = (8, 1)
Simulator.run(): Trial 16
Environment.reset(): Trial set up with start = (6, 3), destination = (1, 3), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 29.0, total_moves = 19, penalty = -3.0, location = (1, 2), destination = (1, 3)
Simulator.run(): Trial 17
Environment.reset(): Trial set up with start = (8, 1), destination = (4, 1), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 22.0, total_moves = 6, penalty = 0, location = (4, 2), destination = (4, 1)
Simulator.run(): Trial 18
Environment.reset(): Trial set up with start = (2, 6), destination = (7, 6), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 40.5, total_moves = 19, penalty = -1.5, location = (7, 5), destination = (7, 6)
Simulator.run(): Trial 19
Environment.reset(): Trial set up with start = (6, 2), destination = (1, 6), deadline = 45
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 50.5, total_moves = 41, penalty = -7.5, location = (2, 6), destination = (1, 6)
Simulator.run(): Trial 20
Environment.reset(): Trial set up with start = (5, 6), destination = (8, 5), deadline = 20
LearningAgent.update(): total_reward = 20.5, total_moves = 21, penalty = -3.5, location = (8, 1), destination = (8, 5)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 21
Environment.reset(): Trial set up with start = (6, 1), destination = (2, 2), deadline = 25
LearningAgent.update(): total_reward = 32.0, total_moves = 26, penalty = -4.0, location = (1, 5), destination = (2, 2)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 22
Environment.reset(): Trial set up with start = (2, 3), destination = (5, 1), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 39.0, total_moves = 25, penalty = -5.0, location = (5, 2), destination = (5, 1)
Simulator.run(): Trial 23
Environment.reset(): Trial set up with start = (5, 2), destination = (8, 4), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 15.0, total_moves = 5, penalty = -1.0, location = (7, 4), destination = (8, 4)
Simulator.run(): Trial 24
Environment.reset(): Trial set up with start = (8, 1), destination = (1, 5), deadline = 55
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 22.0, total_moves = 11, penalty = -2.0, location = (2, 5), destination = (1, 5)
Simulator.run(): Trial 25
Environment.reset(): Trial set up with start = (4, 5), destination = (7, 6), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 21.0, total_moves = 8, penalty = -1.0, location = (7, 5), destination = (7, 6)
Simulator.run(): Trial 26
Environment.reset(): Trial set up with start = (2, 6), destination = (8, 4), deadline = 40
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 26.5, total_moves = 14, penalty = -1.5, location = (8, 3), destination = (8, 4)
Simulator.run(): Trial 27
Environment.reset(): Trial set up with start = (5, 6), destination = (1, 3), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 32.0, total_moves = 30, penalty = -8.0, location = (2, 3), destination = (1, 3)
Simulator.run(): Trial 28
Environment.reset(): Trial set up with start = (6, 2), destination = (4, 4), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 21.5, total_moves = 13, penalty = -2.5, location = (4, 5), destination = (4, 4)
Simulator.run(): Trial 29
Environment.reset(): Trial set up with start = (5, 3), destination = (1, 2), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 23.0, total_moves = 9, penalty = -1.0, location = (1, 3), destination = (1, 2)
Simulator.run(): Trial 30
Environment.reset(): Trial set up with start = (8, 6), destination = (5, 5), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 28.0, total_moves = 14, penalty = -2.0, location = (5, 4), destination = (5, 5)
Simulator.run(): Trial 31
Environment.reset(): Trial set up with start = (7, 2), destination = (4, 1), deadline = 20
LearningAgent.update(): total_reward = 20.5, total_moves = 21, penalty = -3.5, location = (4, 5), destination = (4, 1)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 32
Environment.reset(): Trial set up with start = (2, 2), destination = (7, 5), deadline = 40
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 33.5, total_moves = 21, penalty = -2.5, location = (8, 5), destination = (7, 5)
Simulator.run(): Trial 33
Environment.reset(): Trial set up with start = (1, 1), destination = (5, 6), deadline = 45
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 37.5, total_moves = 26, penalty = -4.5, location = (5, 5), destination = (5, 6)
Simulator.run(): Trial 34
Environment.reset(): Trial set up with start = (8, 1), destination = (4, 1), deadline = 20
LearningAgent.update(): total_reward = 25.0, total_moves = 21, penalty = -3.0, location = (5, 5), destination = (4, 1)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 35
Environment.reset(): Trial set up with start = (2, 2), destination = (8, 3), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 24.5, total_moves = 11, penalty = -1.5, location = (7, 3), destination = (8, 3)
Simulator.run(): Trial 36
Environment.reset(): Trial set up with start = (2, 2), destination = (6, 6), deadline = 40
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 22.5, total_moves = 11, penalty = -1.5, location = (5, 6), destination = (6, 6)
Simulator.run(): Trial 37
Environment.reset(): Trial set up with start = (5, 5), destination = (7, 1), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 30.5, total_moves = 14, penalty = -1.5, location = (7, 2), destination = (7, 1)
Simulator.run(): Trial 38
Environment.reset(): Trial set up with start = (1, 5), destination = (5, 2), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 31.0, total_moves = 14, penalty = -1.0, location = (5, 3), destination = (5, 2)
Simulator.run(): Trial 39
Environment.reset(): Trial set up with start = (4, 4), destination = (2, 2), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 26.5, total_moves = 12, penalty = -1.5, location = (2, 3), destination = (2, 2)
Simulator.run(): Trial 40
Environment.reset(): Trial set up with start = (5, 2), destination = (3, 5), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 23.0, total_moves = 11, penalty = -1.0, location = (3, 4), destination = (3, 5)
Simulator.run(): Trial 41
Environment.reset(): Trial set up with start = (5, 6), destination = (2, 1), deadline = 40
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 47.0, total_moves = 29, penalty = -3.0, location = (2, 2), destination = (2, 1)
Simulator.run(): Trial 42
Environment.reset(): Trial set up with start = (5, 2), destination = (2, 3), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 21.5, total_moves = 12, penalty = -2.5, location = (2, 4), destination = (2, 3)
Simulator.run(): Trial 43
Environment.reset(): Trial set up with start = (1, 1), destination = (5, 4), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 21.0, total_moves = 13, penalty = -3.0, location = (5, 3), destination = (5, 4)
Simulator.run(): Trial 44
Environment.reset(): Trial set up with start = (5, 6), destination = (5, 2), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 28.5, total_moves = 18, penalty = -3.5, location = (5, 3), destination = (5, 2)
Simulator.run(): Trial 45
Environment.reset(): Trial set up with start = (6, 5), destination = (8, 1), deadline = 30
LearningAgent.update(): total_reward = 27.5, total_moves = 31, penalty = -6.5, location = (5, 1), destination = (8, 1)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 46
Environment.reset(): Trial set up with start = (8, 2), destination = (1, 2), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 31.5, total_moves = 19, penalty = -2.5, location = (1, 1), destination = (1, 2)
Simulator.run(): Trial 47
Environment.reset(): Trial set up with start = (5, 5), destination = (8, 3), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 27.5, total_moves = 16, penalty = -2.5, location = (8, 2), destination = (8, 3)
Simulator.run(): Trial 48
Environment.reset(): Trial set up with start = (8, 4), destination = (5, 1), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 40.5, total_moves = 28, penalty = -3.5, location = (5, 2), destination = (5, 1)
Simulator.run(): Trial 49
Environment.reset(): Trial set up with start = (7, 1), destination = (2, 5), deadline = 45
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 24.5, total_moves = 11, penalty = -1.5, location = (2, 6), destination = (2, 5)
Simulator.run(): Trial 50
Environment.reset(): Trial set up with start = (1, 2), destination = (8, 5), deadline = 50
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 40.5, total_moves = 36, penalty = -7.5, location = (8, 4), destination = (8, 5)
Simulator.run(): Trial 51
Environment.reset(): Trial set up with start = (2, 5), destination = (5, 3), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 30.0, total_moves = 23, penalty = -6.0, location = (5, 2), destination = (5, 3)
Simulator.run(): Trial 52
Environment.reset(): Trial set up with start = (1, 6), destination = (8, 2), deadline = 55
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 24.0, total_moves = 16, penalty = -4.0, location = (8, 3), destination = (8, 2)
Simulator.run(): Trial 53
Environment.reset(): Trial set up with start = (2, 5), destination = (1, 1), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 30.0, total_moves = 15, penalty = -2.0, location = (1, 2), destination = (1, 1)
Simulator.run(): Trial 54
Environment.reset(): Trial set up with start = (1, 2), destination = (7, 2), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 24.0, total_moves = 12, penalty = -2.0, location = (6, 2), destination = (7, 2)
Simulator.run(): Trial 55
Environment.reset(): Trial set up with start = (1, 6), destination = (5, 2), deadline = 40
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 51.0, total_moves = 38, penalty = -7.0, location = (5, 3), destination = (5, 2)
Simulator.run(): Trial 56
Environment.reset(): Trial set up with start = (4, 1), destination = (6, 5), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 33.0, total_moves = 14, penalty = -1.0, location = (6, 4), destination = (6, 5)
Simulator.run(): Trial 57
Environment.reset(): Trial set up with start = (1, 3), destination = (5, 6), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 37.0, total_moves = 22, penalty = -3.0, location = (5, 5), destination = (5, 6)
Simulator.run(): Trial 58
Environment.reset(): Trial set up with start = (6, 4), destination = (1, 6), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 31.0, total_moves = 14, penalty = -1.0, location = (1, 5), destination = (1, 6)
Simulator.run(): Trial 59
Environment.reset(): Trial set up with start = (5, 2), destination = (8, 6), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 25.5, total_moves = 9, penalty = -0.5, location = (8, 5), destination = (8, 6)
Simulator.run(): Trial 60
Environment.reset(): Trial set up with start = (1, 5), destination = (6, 1), deadline = 45
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 25.5, total_moves = 9, penalty = -0.5, location = (6, 2), destination = (6, 1)
Simulator.run(): Trial 61
Environment.reset(): Trial set up with start = (6, 2), destination = (1, 3), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 32.5, total_moves = 20, penalty = -3.5, location = (1, 2), destination = (1, 3)
Simulator.run(): Trial 62
Environment.reset(): Trial set up with start = (1, 5), destination = (4, 3), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 24.0, total_moves = 20, penalty = -4.0, location = (4, 4), destination = (4, 3)
Simulator.run(): Trial 63
Environment.reset(): Trial set up with start = (3, 5), destination = (2, 2), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 33.0, total_moves = 14, penalty = -1.0, location = (2, 3), destination = (2, 2)
Simulator.run(): Trial 64
Environment.reset(): Trial set up with start = (1, 3), destination = (4, 6), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 44.0, total_moves = 23, penalty = -2.0, location = (4, 5), destination = (4, 6)
Simulator.run(): Trial 65
Environment.reset(): Trial set up with start = (8, 6), destination = (3, 6), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 24.5, total_moves = 11, penalty = -1.5, location = (3, 5), destination = (3, 6)
Simulator.run(): Trial 66
Environment.reset(): Trial set up with start = (6, 4), destination = (3, 5), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 30.5, total_moves = 14, penalty = -1.5, location = (3, 4), destination = (3, 5)
Simulator.run(): Trial 67
Environment.reset(): Trial set up with start = (1, 2), destination = (8, 6), deadline = 55
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 32.5, total_moves = 15, penalty = -1.5, location = (8, 5), destination = (8, 6)
Simulator.run(): Trial 68
Environment.reset(): Trial set up with start = (7, 6), destination = (6, 3), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 18.0, total_moves = 4, penalty = 0, location = (6, 2), destination = (6, 3)
Simulator.run(): Trial 69
Environment.reset(): Trial set up with start = (8, 6), destination = (3, 3), deadline = 40
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 37.5, total_moves = 20, penalty = -2.5, location = (3, 4), destination = (3, 3)
Simulator.run(): Trial 70
Environment.reset(): Trial set up with start = (7, 4), destination = (2, 2), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 38.5, total_moves = 24, penalty = -3.5, location = (2, 3), destination = (2, 2)
Simulator.run(): Trial 71
Environment.reset(): Trial set up with start = (6, 6), destination = (2, 3), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 46.0, total_moves = 32, penalty = -6.0, location = (2, 2), destination = (2, 3)
Simulator.run(): Trial 72
Environment.reset(): Trial set up with start = (7, 2), destination = (3, 1), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 17.5, total_moves = 5, penalty = -0.5, location = (4, 1), destination = (3, 1)
Simulator.run(): Trial 73
Environment.reset(): Trial set up with start = (2, 5), destination = (7, 6), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 25.5, total_moves = 14, penalty = -2.5, location = (6, 6), destination = (7, 6)
Simulator.run(): Trial 74
Environment.reset(): Trial set up with start = (4, 2), destination = (7, 3), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 21.0, total_moves = 11, penalty = -1.0, location = (7, 2), destination = (7, 3)
Simulator.run(): Trial 75
Environment.reset(): Trial set up with start = (4, 2), destination = (2, 5), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 27.0, total_moves = 14, penalty = -1.0, location = (2, 4), destination = (2, 5)
Simulator.run(): Trial 76
Environment.reset(): Trial set up with start = (6, 6), destination = (6, 2), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 23.5, total_moves = 8, penalty = -0.5, location = (6, 3), destination = (6, 2)
Simulator.run(): Trial 77
Environment.reset(): Trial set up with start = (1, 3), destination = (5, 4), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 32.5, total_moves = 16, penalty = -1.5, location = (5, 3), destination = (5, 4)
Simulator.run(): Trial 78
Environment.reset(): Trial set up with start = (6, 2), destination = (8, 6), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 27.5, total_moves = 20, penalty = -4.5, location = (8, 5), destination = (8, 6)
Simulator.run(): Trial 79
Environment.reset(): Trial set up with start = (4, 4), destination = (8, 4), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 33.5, total_moves = 19, penalty = -2.5, location = (8, 3), destination = (8, 4)
Simulator.run(): Trial 80
Environment.reset(): Trial set up with start = (4, 3), destination = (1, 5), deadline = 25
LearningAgent.update(): total_reward = 23.0, total_moves = 26, penalty = -5.0, location = (6, 6), destination = (1, 5)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 81
Environment.reset(): Trial set up with start = (1, 5), destination = (6, 4), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 40.5, total_moves = 24, penalty = -3.5, location = (6, 5), destination = (6, 4)
Simulator.run(): Trial 82
Environment.reset(): Trial set up with start = (3, 4), destination = (1, 1), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 40.5, total_moves = 19, penalty = -1.5, location = (1, 2), destination = (1, 1)
Simulator.run(): Trial 83
Environment.reset(): Trial set up with start = (5, 5), destination = (7, 2), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 15.0, total_moves = 5, penalty = -1.0, location = (7, 1), destination = (7, 2)
Simulator.run(): Trial 84
Environment.reset(): Trial set up with start = (5, 1), destination = (2, 2), deadline = 20
LearningAgent.update(): total_reward = 24.5, total_moves = 21, penalty = -3.5, location = (3, 5), destination = (2, 2)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 85
Environment.reset(): Trial set up with start = (6, 6), destination = (2, 3), deadline = 35
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 22.0, total_moves = 12, penalty = -2.0, location = (2, 4), destination = (2, 3)
Simulator.run(): Trial 86
Environment.reset(): Trial set up with start = (3, 3), destination = (5, 6), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 34.5, total_moves = 21, penalty = -3.5, location = (5, 5), destination = (5, 6)
Simulator.run(): Trial 87
Environment.reset(): Trial set up with start = (3, 4), destination = (5, 6), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 22.0, total_moves = 7, penalty = 0, location = (5, 5), destination = (5, 6)
Simulator.run(): Trial 88
Environment.reset(): Trial set up with start = (3, 5), destination = (7, 4), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 22.0, total_moves = 11, penalty = -2.0, location = (7, 5), destination = (7, 4)
Simulator.run(): Trial 89
Environment.reset(): Trial set up with start = (4, 5), destination = (7, 6), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 17.0, total_moves = 6, penalty = -1.0, location = (6, 6), destination = (7, 6)
Simulator.run(): Trial 90
Environment.reset(): Trial set up with start = (4, 5), destination = (7, 6), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 33.0, total_moves = 14, penalty = -1.0, location = (7, 5), destination = (7, 6)
Simulator.run(): Trial 91
Environment.reset(): Trial set up with start = (3, 1), destination = (1, 6), deadline = 35
LearningAgent.update(): total_reward = 37.5, total_moves = 36, penalty = -6.5, location = (2, 4), destination = (1, 6)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 92
Environment.reset(): Trial set up with start = (4, 3), destination = (1, 1), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 23.5, total_moves = 12, penalty = -2.5, location = (1, 2), destination = (1, 1)
Simulator.run(): Trial 93
Environment.reset(): Trial set up with start = (2, 1), destination = (5, 3), deadline = 25
LearningAgent.update(): total_reward = 24.5, total_moves = 26, penalty = -5.5, location = (5, 5), destination = (5, 3)
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 94
Environment.reset(): Trial set up with start = (6, 2), destination = (8, 4), deadline = 20
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 18.0, total_moves = 4, penalty = 0, location = (8, 3), destination = (8, 4)
Simulator.run(): Trial 95
Environment.reset(): Trial set up with start = (6, 6), destination = (7, 2), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 13.5, total_moves = 3, penalty = -0.5, location = (7, 1), destination = (7, 2)
Simulator.run(): Trial 96
Environment.reset(): Trial set up with start = (2, 5), destination = (4, 2), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 34.0, total_moves = 19, penalty = -2.0, location = (4, 3), destination = (4, 2)
Simulator.run(): Trial 97
Environment.reset(): Trial set up with start = (6, 3), destination = (1, 3), deadline = 25
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 21.5, total_moves = 7, penalty = -0.5, location = (1, 2), destination = (1, 3)
Simulator.run(): Trial 98
Environment.reset(): Trial set up with start = (2, 2), destination = (7, 1), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 22.0, total_moves = 6, penalty = 0, location = (7, 2), destination = (7, 1)
Simulator.run(): Trial 99
Environment.reset(): Trial set up with start = (4, 2), destination = (2, 6), deadline = 30
Environment.act(): Primary agent has reached destination!
LearningAgent.update(): total_reward = 23.5, total_moves = 8, penalty = -0.5, location = (2, 5), destination = (2, 6)
